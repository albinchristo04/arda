name: Scrape 720pStream Data

on:
  schedule:
    # Run every 6 hours - FIXED: was '0 */6 * *'* now is '0 */6 * * *'
    - cron: '0 */6 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml selenium undetected-chromedriver
          # Install Chrome
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          # Check if requirements.txt exists and install
          if [ -f "requirements.txt" ]; then
            pip install -r requirements.txt
          fi
          
      - name: Run scraper
        run: |
          python scraper_runner.py
          
      - name: Commit and push if changed
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add -A
          git diff --quiet && git diff --staged --quiet || (git commit -m "Update scraped data - $(date -u)" && git push)

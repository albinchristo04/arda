name: StreamBTW Sports Data Extractor

on:
  # Run on schedule (every 3 hours for live sports)
  schedule:
    - cron: '0 */3 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      extract_playable:
        description: 'Extract playable M3U8 links (slow, comprehensive)'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      create_html:
        description: 'Create HTML view'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
      create_readme:
        description: 'Generate README'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
  
  # Run on push to main branch
  push:
    branches:
      - main
    paths:
      - 'streambtw_extractor.py'
      - '.github/workflows/streambtw_extractor.yml'

jobs:
  extract-and-store:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml
      
      - name: Run extractor
        run: |
          python streambtw_extractor.py
        env:
          EXTRACT_PLAYABLE: ${{ github.event.inputs.extract_playable || 'true' }}
          CREATE_HTML: ${{ github.event.inputs.create_html || 'false' }}
      
      - name: Check if data file exists
        id: check_file
        run: |
          if [ -f "streambtw_data.json" ]; then
            echo "file_exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Data file created successfully"
            
            # Show file size
            FILE_SIZE=$(du -h streambtw_data.json | cut -f1)
            echo "üì¶ File size: $FILE_SIZE"
            
            # Show item count
            ITEM_COUNT=$(jq '.total_items' streambtw_data.json)
            echo "üìä Total items: $ITEM_COUNT"
          else
            echo "file_exists=false" >> $GITHUB_OUTPUT
            echo "‚ùå Data file not created"
            exit 1
          fi
      
      - name: Generate README
        if: steps.check_file.outputs.file_exists == 'true' && github.event.inputs.create_readme == 'true'
        run: |
          python - <<'EOF'
          import json
          from datetime import datetime
          
          with open('streambtw_data.json', 'r') as f:
              data = json.load(f)
          
          readme = f"""# StreamBTW Sports Data
          
          üèÜ Automated extraction of sports streaming events from StreamBTW
          
          ## üìä Statistics
          
          - **Last Updated**: {data['last_updated']}
          - **Total Events**: {data['total_items']}
          - **Sports Categories**: {data['sports_count']}
          """
          
          if 'm3u8_extracted' in data and data['m3u8_extracted'] > 0:
              readme += f"- **M3U8 Streams Extracted**: {data['m3u8_extracted']}\n"
              readme += f"- **Accessible Streams**: {data['accessible_streams']}\n"
          
          readme += "\n## üèÖ Available Sports\n\n"
          
          for sport, items in sorted(data['by_sport'].items()):
              icon = items[0]['icon'] if items else "üéØ"
              m3u8_count = sum(1 for i in items if 'playable_link' in i and i['playable_link'].get('m3u8_url'))
              if m3u8_count > 0:
                  readme += f"- {icon} **{sport}**: {len(items)} events ({m3u8_count} with M3U8)\n"
              else:
                  readme += f"- {icon} **{sport}**: {len(items)} events\n"
          
          readme += """
          
          ## üìÅ Files
          
          - `streambtw_data.json` - Complete data in JSON format
          
          ## üîÑ Update Frequency
          
          This data is automatically updated every 3 hours.
          
          ---
          
          *Generated automatically by GitHub Actions*
          """
          
          with open('STREAMBTW_README.md', 'w') as f:
              f.write(readme)
          
          print("‚úÖ README generated")
          EOF
      
      - name: Commit and push results
        if: steps.check_file.outputs.file_exists == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add files
          git add streambtw_data.json || echo "No JSON to add"
          
          # Conditionally add other files if they exist
          [ -f "streambtw_data.html" ] && git add streambtw_data.html
          [ -f "STREAMBTW_README.md" ] && git add STREAMBTW_README.md
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Get stats for commit message
            ITEM_COUNT=$(jq '.total_items' streambtw_data.json)
            SPORTS_COUNT=$(jq '.sports_count' streambtw_data.json)
            M3U8_COUNT=$(jq '.m3u8_extracted // 0' streambtw_data.json)
            
            if [ "$M3U8_COUNT" -gt 0 ]; then
              git commit -m "Update StreamBTW data - $(date +'%Y-%m-%d %H:%M:%S UTC') | Events: $ITEM_COUNT | Sports: $SPORTS_COUNT | M3U8: $M3U8_COUNT"
            else
              git commit -m "Update StreamBTW data - $(date +'%Y-%m-%d %H:%M:%S UTC') | Events: $ITEM_COUNT | Sports: $SPORTS_COUNT"
            fi
            git push
          fi
      
      - name: Upload artifacts
        if: always() && steps.check_file.outputs.file_exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: streambtw-data-${{ github.run_number }}
          path: |
            streambtw_data.json
            streambtw_data.html
            STREAMBTW_README.md
          retention-days: 7
      
      - name: Deploy to GitHub Pages
        if: steps.check_file.outputs.file_exists == 'true' && github.ref == 'refs/heads/main'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .
          publish_branch: gh-pages
          enable_jekyll: false
          keep_files: false
          exclude_assets: '.github/**'

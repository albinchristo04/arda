# .github/workflows/daddylive-scraper.yml
name: Daddylive Scraper

on:
  schedule:
    - cron: "0 * * * *"  # Every hour
  workflow_dispatch:     # Manual run

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 python-dateutil

      - name: Run Daddylive scraper
        working-directory: ./script.module.jetextractors/lib/jetextractors/extractors
        run: |
          mkdir -p ../../../data
          python3 - <<EOF
import sys
import json

sys.path.insert(0, "../..")  # allow importing util/models

from daddylive import Daddylive

scraper = Daddylive()
items = scraper.get_items()

json_items = []
for i in items:
    json_items.append({
        "title": i.title,
        "league": getattr(i, "league", ""),
        "starttime": str(getattr(i, "starttime", "")),
        "links": [{"name": l.name, "address": l.address} for l in getattr(i, "links", [])]
    })

with open("../../../data/daddylive.json", "w") as f:
    json.dump(json_items, f, indent=2)

print(f"Saved {len(json_items)} items to data/daddylive.json")
EOF

      - name: Commit and push JSON
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add data/daddylive.json
          git commit -m "Update Daddylive schedule JSON [skip ci]" || echo "No changes to commit"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

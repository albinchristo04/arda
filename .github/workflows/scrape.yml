name: Fetch Daddylive Events

on:
  schedule:
    - cron: "*/30 * * * *" # every 30 minutes
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 certifi

      - name: Fetch events and channels
        run: |
          python - <<'PY'
          import requests, json, re, sys
          from bs4 import BeautifulSoup
          from urllib.parse import urljoin, urlparse
          import certifi, urllib3

          BASE = "https://dlhd.dad"
          HEADERS = {
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                            "AppleWebKit/537.36 (KHTML, like Gecko) "
                            "Chrome/126.0.0.0 Safari/537.36",
              "Referer": BASE + "/",
              "Origin": BASE
          }

          session = requests.Session()
          session.headers.update(HEADERS)

          def safe_get(url):
              try:
                  return session.get(url, timeout=20, verify=certifi.where())
              except requests.exceptions.SSLError:
                  urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
                  return session.get(url, timeout=20, verify=False)

          def resolve_stream_page(url):
              try:
                  r = safe_get(url)
                  soup = BeautifulSoup(r.text, "html.parser")
                  iframe = soup.select_one("iframe#thatframe") or soup.find("iframe")
                  if not iframe or not iframe.get("src"):
                      return None
                  iframe_url = iframe["src"]
                  if not iframe_url.startswith("http"):
                      iframe_url = urljoin(BASE, iframe_url)

                  r2 = safe_get(iframe_url)
                  m = re.search(r"(https?://[^\s\"']+\.m3u8[^\s\"']*)", r2.text)
                  if not m:
                      return None
                  m3u8_url = m.group(1)

                  parsed = urlparse(iframe_url)
                  origin = f"{parsed.scheme}://{parsed.netloc}"
                  referer = iframe_url if iframe_url.endswith("/") else iframe_url + "/"

                  return {
                      "url": m3u8_url,
                      "headers": {
                          "User-Agent": HEADERS["User-Agent"],
                          "Origin": origin,
                          "Referer": referer
                      }
                  }
              except Exception as e:
                  print("Error resolving", url, "->", e, file=sys.stderr)
                  return None

          events = []

          # 1. Sports schedule
          try:
              r = safe_get(BASE + "/schedule/schedule-generated.json")
              schedule = r.json()
              for header, leagues in schedule.items():
                  for league, matches in leagues.items():
                      for match in matches:
                          title = match.get("event")
                          starttime = match.get("time")
                          channels = match.get("channels", [])
                          if isinstance(channels, dict):
                              channels = channels.values()
                          for ch in channels:
                              iframe_url = f"{BASE}/stream/stream-{ch['channel_id']}.php"
                              resolved = resolve_stream_page(iframe_url)
                              events.append({
                                  "title": f"{title} ({league})",
                                  "iframe": iframe_url,
                                  "m3u8": resolved["url"] if resolved else None,
                                  "headers": resolved["headers"] if resolved else None
                              })
          except Exception as e:
              print("Schedule fetch failed:", e, file=sys.stderr)

          # 2. 24/7 channels
          try:
              r = safe_get(BASE + "/daddy.json")
              channels = r.json()
              for ch in channels:
                  title = ch.get("title") or ""
                  iframe_url = ch.get("link")
                  if not iframe_url:
                      continue
                  if not iframe_url.startswith("http"):
                      iframe_url = urljoin(BASE, iframe_url)
                  resolved = resolve_stream_page(iframe_url)
                  events.append({
                      "title": f"{title} (24/7)",
                      "iframe": iframe_url,
                      "m3u8": resolved["url"] if resolved else None,
                      "headers": resolved["headers"] if resolved else None
                  })
          except Exception as e:
              print("24/7 fetch failed:", e, file=sys.stderr)

          with open("events.json", "w", encoding="utf-8") as f:
              json.dump(events, f, indent=2, ensure_ascii=False)

          print("Wrote", len(events), "events")
          PY

      - name: Commit changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add events.json
          git commit -m "Update events.json" || echo "No changes"
          git push
